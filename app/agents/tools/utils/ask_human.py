from typing import Any

from app.agents.context.schema import Message, Role
from app.agents.tools.utils.base import BaseTool
from app.common.logger import logger


class AskHumanTool(BaseTool):
    """ì‘ì—… ìˆ˜í–‰ì— í•„ìš”í•œ ì •ë³´ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ ì‚¬ìš©ìì˜ ì˜ë„ê°€ ëª¨í˜¸í•  ë•Œ, ì‚¬ìš©ìì—ê²Œ ì§ì ‘ ì§ˆë¬¸í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤."""

    name: str = "ask_human"
    description: str = (
        "ì‘ì—…ì„ ê³„ì† ì§„í–‰í•˜ê¸° ì „ì— ì‚¬ìš©ìë¡œë¶€í„° ì¶”ê°€ ì •ë³´ë¥¼ ì–»ê±°ë‚˜ ëª¨í˜¸í•¨ì„ í•´ì†Œí•´ì•¼ í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. "
        "ë‹¤ìŒê³¼ ê°™ì€ ìƒí™©ì— ì‚¬ìš©í•˜ì‹­ì‹œì˜¤: "
        "1. **ì •ë³´ ë¶€ì¡±**: ê³„íš ìˆ˜ë¦½ì´ë‚˜ ë„êµ¬ ì‚¬ìš©ì— í•„ìˆ˜ì ì¸ ì •ë³´(ì˜ˆ: íŒŒì¼ ì´ë¦„, ê²€ìƒ‰ ëŒ€ìƒ)ê°€ ëˆ„ë½ë˜ì—ˆì„ ë•Œ. "
        "2. **ì˜ë„ ëª¨í˜¸**: ì‚¬ìš©ìì˜ ìš”ì²­ì´ ì—¬ëŸ¬ ì˜ë¯¸ë¡œ í•´ì„ë  ìˆ˜ ìˆì–´ ëª…í™•í•œ ë°©í–¥ ì„¤ì •ì´ í•„ìš”í•  ë•Œ. "
        "3. **ì¤‘ìš” í–‰ë™ í™•ì¸**: ë˜ëŒë¦´ ìˆ˜ ì—†ëŠ” ì¤‘ìš”í•œ í–‰ë™(ì˜ˆ: íŒŒì¼ ì‚­ì œ, ë°ì´í„°ë² ì´ìŠ¤ ìˆ˜ì •)ì„ ìˆ˜í–‰í•˜ê¸° ì „ ì‚¬ìš©ìì—ê²Œ ìµœì¢… í™•ì¸ì„ ë°›ì„ ë•Œ."
    )
    parameters: dict[str, Any] = {
        "type": "object",
        "properties": {
            "question_to_ask": {
                "type": "string",
                "description": "The specific, clear, and concise question to ask the user. The question should be phrased to elicit the exact information needed.",
            }
        },
        "required": ["question_to_ask"],
    }

    async def execute(self, question_to_ask: str, agent: Any, **kwargs) -> str:
        try:
            if agent.message_queue:
                await agent.message_queue.put(
                    Message(
                        role=Role.ASSISTANT,
                        content=question_to_ask,
                        metadata={"state": "assistant_finished"},
                    )
                )
            return f"ì‚¬ìš©ìì—ê²Œ {question_to_ask} ì§ˆë¬¸ì„ ì „ë‹¬í•˜ì˜€ìŠµë‹ˆë‹¤."
        except Exception as e:
            error_msg = f"An error occurred during ask human tool execution: {e}"
            logger.exception(error_msg)
            return f"Error: {error_msg}"


class AnswerTool(BaseTool):
    """A tool for delivering direct, non-sourced answers to the user.

    Used for conversational replies or to report search failures.
    """

    name: str = "answer"
    description: str = (
        "ì‚¬ìš©ìì—ê²Œ ì§ì ‘ í…ìŠ¤íŠ¸ ë‹µë³€ì„ ì „ë‹¬í•©ë‹ˆë‹¤. ì´ ë„êµ¬ëŠ” ê²€ìƒ‰ ê²°ê³¼ë‚˜ ì™¸ë¶€ ìë£Œë¥¼ ì¸ìš©í•˜ì§€ ì•Šìœ¼ë©°, "
        "ë‹¤ìŒê³¼ ê°™ì€ ê²½ìš°ì— ì‚¬ìš©ë©ë‹ˆë‹¤: "
        "1. ë‹¨ìˆœí•œ ì¸ì‚¬, ê°ì‚¬ ë“± ì¼ë°˜ì ì¸ ëŒ€í™”ì— ì‘ë‹µí•  ë•Œ. "
        "2. ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œëœ í›„, ìµœì¢… ê²°ë¡ ì´ë‚˜ ìš”ì•½ ë‚´ìš©ì„ ì „ë‹¬í•  ë•Œ. "
        "3. ì‚¬ìš©ìì—ê²Œ ì‹œìŠ¤í…œì˜ ìƒíƒœë‚˜ ì‘ì—… ì‹¤íŒ¨ ì‚¬ì‹¤ì„ ì•Œë ¤ì•¼ í•  ë•Œ."
    )
    parameters: dict[str, Any] = {
        "type": "object",
        "properties": {
            "synthesis_brief": {
                "type": "string",
                "description": "Plannerì— ì˜í•´ ìµœì¢…ì ìœ¼ë¡œ ì¢…í•©ëœ ê²°ë¡ ê³¼ í•µì‹¬ ì •ë³´. ì´ ë¸Œë¦¬í•‘ì—ëŠ” ìµœì¢… ë‹µë³€ ìƒì„±ì„ ìœ„í•œ ëª¨ë“  ë‚´ìš©ê³¼ ìŠ¤íƒ€ì¼ ì§€ì¹¨ì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.",
            }
        },
        "required": ["synthesis_brief"],
    }

    async def execute(self, synthesis_brief: str, agent: Any, **kwargs) -> str:
        try:
            logger.info("ğŸ”§ Executing answer tool ğŸ”§ ")
            tool_msg = Message.tool_message(
                content="Executing answer tool to generate and stream the final response.",
                tool_call_id=agent.tool_calls[0].id,
                name=agent.tool_calls[0].function.name,
                base64_image=None,
            )
            agent.memory.add_message(tool_msg)

            # ìµœì¢… ë‹µë³€ ìƒì„±ì„ ìœ„í•œ ê°„ë‹¨í•œ ì§€ì‹œ í”„ë¡¬í”„íŠ¸
            next_step_prompt = agent.tool_prompts.get(self.name, {}).get(
                "next_step_prompt", ""
            )
            if next_step_prompt:
                next_step_prompt = Message.user_message(
                    next_step_prompt.format(synthesis_brief=synthesis_brief)
                )
                agent.messages += [next_step_prompt]
            else:
                logger.warning("No next step prompt found for answer tool.")

            system_prompt = agent.tool_prompts.get(self.name, {}).get("system_prompt")
            if system_prompt:
                system_prompt = [Message.system_message(system_prompt)]
            else:
                system_prompt = []
                logger.warning("No system prompt found for answer tool.")

            final_content_buffer = ""
            async for chunk in agent.llm.ask_streaming(
                messages=agent.messages,
                system_msgs=system_prompt,
            ):
                delta = chunk.choices[0].delta
                if delta.content:
                    content = delta.content
                    final_content_buffer += content
                    if agent.message_queue:
                        await agent.message_queue.put(
                            Message(
                                role=Role.ASSISTANT,
                                content=content,
                                metadata={"state": "assistant_streaming"},
                            )
                        )

            # ìŠ¤íŠ¸ë¦¬ë° ì¢…ë£Œ í›„ ë©”ëª¨ë¦¬ì— ìµœì¢… ë‹µë³€ ì €ì¥ ë° ì¢…ë£Œ ì‹ í˜¸ ì „ì†¡
            agent.memory.add_message(Message.assistant_message(final_content_buffer))
            if agent.message_queue:
                await agent.message_queue.put(
                    Message(
                        role=Role.ASSISTANT,
                        content=final_content_buffer,
                        metadata={"state": "assistant_finished"},
                    )
                )
            return "Final answer has been successfully streamed to the user."
        except Exception as e:
            error_msg = f"An error occurred during final answer streaming: {e}"
            logger.exception(error_msg)
            return f"Error: {error_msg}"
